**docs/Agent_Creation_Process.md**

# Agent Creation Process

This document delves into how the system creates and manages custom agents, including two approaches for agent logic handling: **in-memory execution** and **file-based generation**. It also covers how AI-assisted tools can be leveraged to create agent code.

## Creating an Agent via API  
When a user creates a new agent (by calling the POST `/agents` endpoint), the system goes through these steps:  

1. **Input Validation**: The request JSON is validated against the `AgentCreate` Pydantic model. The model ensures required fields like `agent_name` and `description` are present.  
2. **Optional Code Generation**: If the user provided an `agent_config` (some code or config), it will be used. If not, the system can generate a default behavior or use an AI to produce code. For instance, the system might create a simple placeholder function that returns a static message containing the description. This happens in the `generate_agent_code` function in the implementation.  
3. **Storing the Agent**: The new agent is inserted into the database (Supabase). This makes it persistent. The `agent_config` (code/logic) is now stored as text in the DB associated with that user and agent name.  
4. **Preparing for Execution**: After storing, the system prepares the agent for execution. Depending on the chosen strategy, it either:  
   - Compiles/loads the code into memory (so it’s ready to call on demand), or  
   - Writes the code to a file in the server (so it can be imported and executed later).  
   This step is handled by the `load_agent_to_runtime` function in the Implementation Guide.

## In-Memory Execution  
In-memory execution means that the agent’s logic is kept in the running application’s memory, typically as a Python function object, after creation. Here’s how it works:  

- When an agent is created, use Python’s `exec()` to execute the agent’s code string in a controlled namespace. For example:  
  ```python
  agent_code = "def agent_main():\n    return 'hello world'"
  namespace = {}
  exec(agent_code, namespace)
  function_obj = namespace.get('agent_main')
  ```  
  Now `function_obj` is a callable Python function for the agent.  
- Store this function in a dictionary for quick access. For example, a global dict:  
  ```python
  AGENTS_REGISTRY = {}  # keys: (user_id, agent_name), value: function
  AGENTS_REGISTRY[(user_id, agent_name)] = function_obj
  ```  
- When a request comes in to execute the agent, simply look up the function and call it:  
  ```python
  func = AGENTS_REGISTRY.get((user_id, agent_name))
  if func:
      result = func()  # execute agent logic
  ```  
- Benefits of in-memory: Fast execution (no file I/O on each call), and simple to implement. Changes can be effective immediately by updating the dict.  

- Drawbacks:  
  - If the application restarts, the in-memory registry is lost (we’d have to reload from the database on startup for persistence).  
  - Memory usage could grow with many agents (though just storing function objects is usually lightweight).  
  - Updates to an agent (if we implement an update endpoint) need to replace the function in memory too.  
  - Security: Executing with `exec` can be dangerous if not sandboxed (discussed later).  

- **Pseudo-code for In-Memory Approach:**  
  ```python
  # At app startup, optionally pre-load all agents from DB
  AGENTS_REGISTRY = {}
  for agent_record in supabase.from_("agents").select("*").execute().data:
      ns = {}
      exec(agent_record["agent_config"], ns)
      if "agent_main" in ns:
          AGENTS_REGISTRY[(agent_record["user_id"], agent_record["agent_name"])] = ns["agent_main"]
  
  def load_agent_to_runtime(user_id, agent_name, code):
      ns = {}
      exec(code, ns)
      AGENTS_REGISTRY[(user_id, agent_name)] = ns.get("agent_main")
  ```  
  Every time an agent is created or updated, call `load_agent_to_runtime`. On execution, fetch from `AGENTS_REGISTRY` and run.  

- **AI-assisted generation**: If the code is generated by an AI, it still goes through this process. The source (human or AI) doesn’t matter for this execution method.

## File-Based Generation  
File-based generation means each agent’s code is stored as a separate Python module file on the server. The process:  

- When an agent is created, a new Python file is created on disk, e.g., in an `agents/` directory. The file could be named using the user_id and agent_name (to keep it unique). For example: `agents/<user_id>__<agent_name>.py` (using `__` or some delimiter if user_id is a UUID).  
  - Example: user `123e4567-e89b-12d3-a456-426614174000` creating agent `weather_bot` might produce file `agents/123e4567-e89b-12d3-a456-426614174000__weather_bot.py`.  
- The content of the file is the `agent_config` code, possibly with some standard structure. For instance, you may ensure the code defines a function `run()` or `agent_main()`. If not already in the code, you could wrap the user’s code or append a call. However, it’s easier to enforce that generated code always has a known function signature.  
- To execute, the system uses Python’s import mechanisms. There are a couple of ways:  
  1. **Dynamic import by module name**: Since we have a consistent module path (the `agents` package), we can do:  
     ```python
     import importlib
     module_name = f"agents.{user_id}__{agent_name}"
     mod = importlib.import_module(module_name)
     result = mod.run()  # or mod.agent_main()
     ```  
     This requires that `agents` is a package (with `__init__.py`). The first time this runs, Python will load the module from the file. On subsequent calls, Python will use the cached module from sys.modules (unless the file changed and we force reload).  
  2. **Import by file path**: Alternatively, use `importlib.util.spec_from_file_location` as shown in the Implementation Guide for `execute_agent_code`. This loads the file explicitly each time, which can reflect any updates to the file immediately.  
- Benefits of file-based:  
  - The agent code persists on disk, so even if the app restarts, you still have the files (though you’d need to re-import them or on startup import all).  
  - It separates user code from running memory until needed, which might reduce memory usage if many agents exist but are seldom called.  
  - It’s easier to inspect or edit agent files directly on disk during development or debugging.  
- Drawbacks:  
  - File I/O on each execution (if not caching modules) can be slightly slower (though usually negligible unless agent is called very frequently).  
  - Managing filenames and ensuring they’re unique and safe (need to sanitize agent_name to not break filesystem).  
  - If agent code needs to be updated, you have to overwrite the file and possibly reload the module (might need to `importlib.reload(mod)` if already imported).  
  - Leaving many files can clutter the environment – consider a cleanup strategy if agents are removed.  

- **Pseudo-code for File-Based Approach:**  
  ```python
  import os
  AGENT_FOLDER = "agents"
  os.makedirs(AGENT_FOLDER, exist_ok=True)
  
  def save_agent_to_file(user_id, agent_name, code):
      filename = f"{user_id}__{agent_name}.py"
      path = os.path.join(AGENT_FOLDER, filename)
      with open(path, "w") as f:
          f.write(code)
      return path
  
  def execute_agent_from_file(user_id, agent_name, test_mode=False):
      filename = f"{user_id}__{agent_name}.py"
      path = os.path.join(AGENT_FOLDER, filename)
      if not os.path.exists(path):
          raise FileNotFoundError("Agent code file not found")
      spec = importlib.util.spec_from_file_location(f"agents.{user_id}__{agent_name}", path)
      module = importlib.util.module_from_spec(spec)
      spec.loader.exec_module(module)
      if hasattr(module, "TEST_MODE"):
          module.TEST_MODE = test_mode
      if hasattr(module, "run"):
          return module.run()
      elif hasattr(module, "agent_main"):
          return module.agent_main()
      else:
          raise RuntimeError("No valid entry point in agent code")
  ```  
  The above ensures that each execution reads the latest file. Alternatively, you could load once and cache, but then you must reload on changes.

## Choosing Between In-Memory and File-Based  
Which approach to use depends on the use case and constraints:

- **Use In-Memory if**: The number of agents is relatively small or moderate, and quick access is needed. If agents are frequently invoked and you want the lowest latency, in-memory might be better. Also, if you’re not worried about losing the registry on restart (because you can reload from DB if needed), it’s simpler.  
- **Use File-Based if**: You expect many agents or large agent code that you don’t want occupying memory until necessary. Or if you want persistence across restarts without reloading all from DB at startup (though you could also load from DB). Also, if you want a clear separation of user code (like treating each agent almost like a plugin module), the file approach is neat.  
- **Hybrid**: It’s possible to combine them: save to file for persistence, but also load into memory for quick calls, perhaps caching the function after the first call. This might be overkill for most scenarios but is an option.

**Security considerations** come into play for both: in-memory uses `exec`, file-based uses dynamic imports – both execute arbitrary code. The next section touches on controlling that.

## AI-Assisted Code Generation  
One of the powerful features envisioned is using AI to help create agent logic from a simple description. Here’s how that can be integrated:  

- When the user calls POST `/agents` and provides a description but no code, the server can call an AI service (like OpenAI’s API) with a prompt to generate code. For example:  
  Prompt: *“Write a Python function named `agent_main` that {does something described}. The function should take no arguments and return a result.”*  
  The AI might return code as a string. We then use that as `agent_config`.  

- **Validation of AI output**: Always treat it as potentially untrusted (even though it’s your AI, it could generate unsafe code by mistake). It’s wise to review or sandbox it. Perhaps run it in test mode first to see if it behaves.  

- **Automating this with tools**: If doing this manually, a developer might use ChatGPT to get a snippet and then paste it. But since this is an API, you’d integrate directly. For initial development, you can simulate AI by returning a canned response (as we did with `generate_agent_code` stub).  

- **Instructing users**: In your README or API docs, explain that if they omit `agent_config`, the system will attempt to generate one. They should provide a clear description. For instance:  
  *Description:* “Calculates the Fibonacci sequence up to N=10 and returns the list.”  
  The AI would ideally produce a function that does that.  

- **Potential enhancements**: Provide a parameter in the POST request like `use_ai=true` to explicitly request generation, or possibly multiple styles of agents (some might be prompt-based for an LLM agent vs code-based).

- **Example AI Generation**:  
  User description: “Greets the user by name.”  
  Generated `agent_config`:  
  ```python
  def agent_main():
      name = "User"  # In a real scenario, we might take input
      return {"message": f"Hello, {name}!"}
  ```  
  This is basic, but an AI could produce more complex logic.  

- Documenting this: It’s good to note in the Implementation Guide that one could integrate with OpenAI by using their SDK (pip install openai) and call `openai.Completion.create(...)` with an appropriate prompt. However, include this as an optional extension to keep the core system offline-capable.

**AI Tool for Development**: Apart from generating agent code at runtime for users, as a developer you can use AI coding assistants to write your code. For example, writing the function to execute agent code or to handle file operations can be sped up with Copilot. Always ensure the suggestions are correct for your scenario. The documentation you’re writing (this content) can also serve as a prompt to such tools if needed.

## Example: End-to-End Agent Creation Scenario  
1. User calls POST `/agents` with `{ "agent_name": "quote_bot", "description": "gives a random famous quote" }`.  
2. Server sees no `agent_config` provided. It calls `generate_agent_code("gives a random famous quote")`.  
3. Suppose the AI returns:  
   ```python
   import random
   quotes = ["To be or not to be.", "I think, therefore I am.", "Stay hungry, stay foolish."]
   def agent_main():
       return {"quote": random.choice(quotes)}
   ```  
4. The server saves this in DB. Then writes it to `agents/<user>__quote_bot.py` and/or execs it into memory.  
5. When user later calls GET `/agents/{user_id}/quote_bot`, the server executes `agent_main()` from that code. The user gets a random quote in response.  

This shows how a simple description turned into a functional agent with minimal user effort, thanks to the AI generation and the system’s integration.

**Note**: We must be careful with the AI step – ensure the environment where AI code runs has limited capabilities. For instance, if the AI returned `os.system("rm -rf /")` as a quote (silly example), our system might execute it blindly. This is where we talk about sandboxing next.

## Summary of Agent Creation  
- Agents can be created with or without directly providing code.  
- In-memory vs file-based are implementation details; both achieve the same end result: making the agent executable via the `/agents/{user_id}/{agent_name}` endpoint.  
- We maintain flexibility to switch approaches or even support both (e.g., a config setting to choose mode).  
- AI-assisted generation is a bonus feature that can significantly enhance user experience. Its implementation can be iterative – start with static or template-based generation, then integrate real AI when confident.  

For important precautions and how to secure the execution of these agents, proceed to **Security_Considerations.md**. Otherwise, for verifying everything works, see **Testing_and_Validation.md**.